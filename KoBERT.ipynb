{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f6c5f86-1183-422e-a1cf-73c3ac26b8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SK KoBERT에서 요구하는 패키지\n",
    "# boto3 <=1.15.18\n",
    "# gluonnlp >= 0.6.0, <=0.10.0\n",
    "# mxnet >= 1.4.0, <=1.7.0.post2\n",
    "# onnxruntime == 1.8.0, <=1.8.0\n",
    "# sentencepiece >= 0.1.6, <=0.1.96\n",
    "# torch >= 1.7.0, <=1.10.1\n",
    "# transformers >= 4.8.1, <=4.8.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "560a7663-b67c-4de2-acde-60c869fd2083",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install git+https://git@github.com/SKTBrain/KoBERT.git@master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6da0b48f-fb9a-474c-a634-6c213c8c3f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "#transformers\n",
    "from transformers import AdamW\n",
    "from transformers.optimization import get_cosine_schedule_with_warmup\n",
    "from transformers import BertModel\n",
    "\n",
    "# torch, nlp를 위한 모듈 로드\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import gluonnlp as nlp\n",
    "import numpy as np\n",
    "\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import sys\n",
    "import re\n",
    "import gc\n",
    "import os\n",
    "\n",
    "# kobert 모듈 로드\n",
    "from kobert.utils import get_tokenizer\n",
    "from kobert.pytorch_kobert import get_pytorch_kobert_model\n",
    "\n",
    "# transformer 모듈 로드\n",
    "from transformers import AdamW\n",
    "from transformers.optimization import get_cosine_schedule_with_warmup\n",
    "from transformers import BertModel\n",
    "\n",
    "# argument\n",
    "import argparse\n",
    "\n",
    "#GPU 사용 시\n",
    "device = torch.device(\"cuda:0\")\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"  # Arrange GPU devices starting from 0\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]= \"0,1\"  # Set the GPU 2 to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc1ed810-e6fa-49c2-830b-d7465fb78821",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./train.csv')[['overview', 'cat3']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c4ca9b9-a06c-4ce5-aae0-64fcc4e06c62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16986, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a6aa185-7360-4b7c-9d1b-1a35e2119986",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overview</th>\n",
       "      <th>cat3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>소안항은 조용한 섬으로 인근해안이 청정해역으로 일찍이 김 양식을 해서 높은 소득을 ...</td>\n",
       "      <td>항구/포구</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>경기도 이천시 모가면에 있는 골프장으로 대중제 18홀이다. 회원제로 개장을 했다가 ...</td>\n",
       "      <td>골프</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>금오산성숯불갈비는 한우고기만을 전문적으로 취급하고 사용하는 부식 자재 또한 유기농법...</td>\n",
       "      <td>한식</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>철판 위에서 요리하는 안동찜닭을 맛볼 수 있는 곳이다. 경상북도 안동시에 있는 한식...</td>\n",
       "      <td>한식</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>※ 영업시간 10:30 ~ 20:30\\n\\n3대에 걸쳐 아귀만을 전문으로 취급하는 ...</td>\n",
       "      <td>한식</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            overview   cat3\n",
       "0  소안항은 조용한 섬으로 인근해안이 청정해역으로 일찍이 김 양식을 해서 높은 소득을 ...  항구/포구\n",
       "1  경기도 이천시 모가면에 있는 골프장으로 대중제 18홀이다. 회원제로 개장을 했다가 ...     골프\n",
       "2  금오산성숯불갈비는 한우고기만을 전문적으로 취급하고 사용하는 부식 자재 또한 유기농법...     한식\n",
       "3  철판 위에서 요리하는 안동찜닭을 맛볼 수 있는 곳이다. 경상북도 안동시에 있는 한식...     한식\n",
       "4  ※ 영업시간 10:30 ~ 20:30\\n\\n3대에 걸쳐 아귀만을 전문으로 취급하는 ...     한식"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "89862b19-a600-4790-8094-d1231aade109",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_overview = []\n",
    "for i in data.iterrows():\n",
    "    add_text = re.sub('[^0-9가-힣MTBATV]',' ',i[1]['cat3'])\n",
    "    new_overview.append(add_text + '에 대한 내용입니다. '+ i[1]['overview'])\n",
    "data['overview'] = new_overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f700cf4f-0599-4d45-a408-232a8aed009a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overview</th>\n",
       "      <th>cat3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>항구 포구에 대한 내용입니다. 소안항은 조용한 섬으로 인근해안이 청정해역으로 일찍이...</td>\n",
       "      <td>항구/포구</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>골프에 대한 내용입니다. 경기도 이천시 모가면에 있는 골프장으로 대중제 18홀이다....</td>\n",
       "      <td>골프</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>한식에 대한 내용입니다. 금오산성숯불갈비는 한우고기만을 전문적으로 취급하고 사용하는...</td>\n",
       "      <td>한식</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            overview   cat3\n",
       "0  항구 포구에 대한 내용입니다. 소안항은 조용한 섬으로 인근해안이 청정해역으로 일찍이...  항구/포구\n",
       "1  골프에 대한 내용입니다. 경기도 이천시 모가면에 있는 골프장으로 대중제 18홀이다....     골프\n",
       "2  한식에 대한 내용입니다. 금오산성숯불갈비는 한우고기만을 전문적으로 취급하고 사용하는...     한식"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "af1e1266-9335-47b7-b168-9b8e0bc659cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = []\n",
    "for ques, label in zip(data['overview'], data['cat3']):\n",
    "    tmp = []   \n",
    "    tmp.append(ques)\n",
    "    tmp.append(str(label))\n",
    "\n",
    "    data_list.append(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a77469db-6ff0-4cec-9221-a4d5801c46b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['항구 포구에 대한 내용입니다. 소안항은 조용한 섬으로 인근해안이 청정해역으로 일찍이 김 양식을 해서 높은 소득을 올리고 있으며 바다낚시터로도 유명하다. 항 주변에 설치된 양식장들은 섬사람들의 부지런한 생활상을 고스 란히 담고 있으며 일몰 때 섬의 정경은 바다의 아름다움을 그대로 품고 있는 듯하다. 또한, 섬에는 각시여 전설, 도둑바위 등의 설화가 전해 내려오고 있으며, 매년 정월 풍어제 풍속이 이어지고 있다.<br>',\n",
       " '항구/포구']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d5e6ea1c-9483-43eb-9657-344d8b75e4b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTDataset(Dataset):\n",
    "    def __init__(self, dataset, sent_idx, label_idx, bert_tokenizer,vocab, max_len,\n",
    "                 pad, pair):\n",
    "   \n",
    "        transform = nlp.data.BERTSentenceTransform(\n",
    "            bert_tokenizer, max_seq_length=max_len,vocab=vocab, pad=pad, pair=pair)\n",
    "        \n",
    "        self.sentences = [transform([i[sent_idx]]) for i in dataset]\n",
    "        self.labels = [np.int32(i[label_idx]) for i in dataset]\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return (self.sentences[i] + (self.labels[i], ))\n",
    "         \n",
    "\n",
    "    def __len__(self):\n",
    "        return (len(self.labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "57a6aa85-4865-4703-891f-913781724518",
   "metadata": {},
   "outputs": [],
   "source": [
    "# kobert 모듈 로드\n",
    "from kobert.utils import get_tokenizer\n",
    "from kobert.pytorch_kobert import get_pytorch_kobert_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ff7ec46b-a3f4-45cb-b146-d6d680db5263",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# 학습 데이터셋 구축 클래스\n",
    "class BERTDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, dataset, sent_idx, label_idx, bert_tokenizer, max_len,\n",
    "                 pad, pair):\n",
    "        transform = nlp.data.BERTSentenceTransform(\n",
    "            bert_tokenizer, max_seq_length=max_len, pad=pad, pair=pair)\n",
    "\n",
    "        self.sentences = [transform([i[sent_idx]]) for i in dataset]\n",
    "        self.labels = [np.int32(i[label_idx]) for i in dataset]\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return (self.sentences[i] + (self.labels[i], ))\n",
    "\n",
    "    def __len__(self):\n",
    "        return (len(self.labels))\n",
    "\n",
    "    \n",
    "# BERT 분류기 클래스\n",
    "class BERTClassifier(nn.Module):\n",
    "    \n",
    "    def __init__(self,\n",
    "                 bert,\n",
    "                 hidden_size = 768,\n",
    "                 num_classes = 128, # softmax 사용 <- binary일 경우는 2\n",
    "                 dr_rate=None,\n",
    "                 params=None):\n",
    "        super(BERTClassifier, self).__init__()\n",
    "        self.bert = bert\n",
    "        self.dr_rate = dr_rate\n",
    "                 \n",
    "        self.classifier = nn.Linear(hidden_size , num_classes)\n",
    "        if dr_rate:\n",
    "            self.dropout = nn.Dropout(p=dr_rate)\n",
    "    \n",
    "    def gen_attention_mask(self, token_ids, valid_length):\n",
    "        attention_mask = torch.zeros_like(token_ids)\n",
    "        for i, v in enumerate(valid_length):\n",
    "            attention_mask[i][:v] = 1\n",
    "#         print(attention_mask)\n",
    "        return attention_mask.float()\n",
    "\n",
    "    def forward(self, token_ids, valid_length, segment_ids):\n",
    "        attention_mask = self.gen_attention_mask(token_ids, valid_length)\n",
    "        \n",
    "        _, pooler = self.bert(input_ids = token_ids, token_type_ids = segment_ids.long(), attention_mask = attention_mask.float().to(token_ids.device))\n",
    "        if self.dr_rate:\n",
    "            out = self.dropout(pooler)\n",
    "        return self.classifier(out), pooler    \n",
    "    \n",
    "\n",
    "# 학습 평가 지표인 accuracy 계산 -> 얼마나 타겟값을 많이 맞추었는가\n",
    "def calc_accuracy(X,Y):\n",
    "    max_vals, max_indices = torch.max(X, 1)\n",
    "    train_acc = (max_indices == Y).sum().data.cpu().numpy()/max_indices.size()[0]\n",
    "    return train_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7c5375eb-8742-4050-8579-32d2c3b2210a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cached model. /home/rok/Multimodal_Clf/Multimodal-Clf/.cache/kobert_v1.zip\n",
      "using cached model. /home/rok/Multimodal_Clf/Multimodal-Clf/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n",
      "using cached model. /home/rok/Multimodal_Clf/Multimodal-Clf/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n"
     ]
    }
   ],
   "source": [
    "bertmodel, vocab = get_pytorch_kobert_model()\n",
    "tokenizer = get_tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "af276183-8aa9-491f-9764-77a8d7af6f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\") #GPU 사용 시\n",
    "#device = torch.device(\"cpu\") #CPU 사용 시\n",
    "torch.cuda.is_available()\n",
    "\n",
    "# 토크나이저 생성\n",
    "tok = nlp.data.BERTSPTokenizer(tokenizer, vocab, lower=False)\n",
    "\n",
    "model = BERTClassifier(bertmodel, dr_rate=0.2).to(device)\n",
    "# model = nn.DataParallel(model, device_ids=[0,1])\n",
    "model.cuda()\n",
    "model = nn.DataParallel(model).to(device)\n",
    "\n",
    "# Prepare optimizer and schedule (linear warmup and decay)\n",
    "no_decay = ['bias', 'LayerNorm.weight']\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
    "    {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8f68f592-e9e1-4dfd-abf0-beb1c2a8b895",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([120,   8, 118,  73,  58,  90,  85,  91,  94,  97,  12,  31,  67,\n",
       "        41, 101, 119, 105,  59, 100,  72,  96,  86, 121,   0,  37,  11,\n",
       "        54,  44,  25,   9,  20,  48, 115,  53,  16,  15,  92,  95, 127,\n",
       "        82,  61,  84,  52,   3,  93,  43,  35,   5, 116,  57,  99,  27,\n",
       "        19,   7,  13,   4,  71,  79,  34,  29,  69,  10, 112,  77,  60,\n",
       "       122, 114,  17,  18, 126,  38, 107,  39, 111,  81,  42,  63,  46,\n",
       "       125, 102,  78,  30,  21, 103,  49,  26,  24,  80, 113,  83,   6,\n",
       "        56,  40,  98,  32,  70,  47, 110,  33, 104, 109,  45,  22,   2,\n",
       "        14,  66,  23,  55,  65,  76, 124,  64,  74,  89,  87, 117, 123,\n",
       "        28,  51,   1,  50,  62,  75, 106,  68,  36,  88, 108])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "  \n",
    "# label_encoder object knows how to understand word labels.\n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "  \n",
    "# Encode labels in column 'species'.\n",
    "data['cat3']= label_encoder.fit_transform(data['cat3'])\n",
    "data['cat3'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "299b957b-9fb7-414f-a6dd-4b51f09ecbed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_to_chr = {}\n",
    "for i in data['cat3'].unique():\n",
    "    num_to_chr[i] = label_encoder.inverse_transform(np.array([i]))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "33b91496-59d6-406c-b243-25f533385f38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['테마공원'], dtype=object)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_encoder.inverse_transform(np.array([111]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "46249866-fb16-4bbb-955a-e0ee994e79ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(data['cat3'].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2174e70e-00c4-4827-a5be-d014552b9ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.rename(columns={'overview':'content', 'cat3':'label'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f5855f82-ed8e-4e63-ac03-cbcf37cad926",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>항구 포구에 대한 내용입니다. 소안항은 조용한 섬으로 인근해안이 청정해역으로 일찍이...</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>골프에 대한 내용입니다. 경기도 이천시 모가면에 있는 골프장으로 대중제 18홀이다....</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>한식에 대한 내용입니다. 금오산성숯불갈비는 한우고기만을 전문적으로 취급하고 사용하는...</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>한식에 대한 내용입니다. 철판 위에서 요리하는 안동찜닭을 맛볼 수 있는 곳이다. 경...</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>한식에 대한 내용입니다. ※ 영업시간 10:30 ~ 20:30\\n\\n3대에 걸쳐 아...</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16981</th>\n",
       "      <td>한식에 대한 내용입니다. 해발 12000m에 자리한 식담겸 카페점문점이다.&lt;br&gt;곤...</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16982</th>\n",
       "      <td>모텔에 대한 내용입니다. 설악힐호텔은 동해고속도로 속초톨게이트에서 멀지 않은 관광로...</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16983</th>\n",
       "      <td>모텔에 대한 내용입니다. 충남 서산시 중심가에 위치한 줌모텔은 프라이버스가 보장되는...</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16984</th>\n",
       "      <td>야영장 오토캠핑장에 대한 내용입니다. 토토큰바위캠핑장은 경기도 가평지역 내에서도 청...</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16985</th>\n",
       "      <td>사찰에 대한 내용입니다. 포천의 진산으로 불리우는 왕방산(王訪山)에는 천년의 역사를...</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16986 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 content  label\n",
       "0      항구 포구에 대한 내용입니다. 소안항은 조용한 섬으로 인근해안이 청정해역으로 일찍이...    120\n",
       "1      골프에 대한 내용입니다. 경기도 이천시 모가면에 있는 골프장으로 대중제 18홀이다....      8\n",
       "2      한식에 대한 내용입니다. 금오산성숯불갈비는 한우고기만을 전문적으로 취급하고 사용하는...    118\n",
       "3      한식에 대한 내용입니다. 철판 위에서 요리하는 안동찜닭을 맛볼 수 있는 곳이다. 경...    118\n",
       "4      한식에 대한 내용입니다. ※ 영업시간 10:30 ~ 20:30\\n\\n3대에 걸쳐 아...    118\n",
       "...                                                  ...    ...\n",
       "16981  한식에 대한 내용입니다. 해발 12000m에 자리한 식담겸 카페점문점이다.<br>곤...    118\n",
       "16982  모텔에 대한 내용입니다. 설악힐호텔은 동해고속도로 속초톨게이트에서 멀지 않은 관광로...     31\n",
       "16983  모텔에 대한 내용입니다. 충남 서산시 중심가에 위치한 줌모텔은 프라이버스가 보장되는...     31\n",
       "16984  야영장 오토캠핑장에 대한 내용입니다. 토토큰바위캠핑장은 경기도 가평지역 내에서도 청...     73\n",
       "16985  사찰에 대한 내용입니다. 포천의 진산으로 불리우는 왕방산(王訪山)에는 천년의 역사를...     52\n",
       "\n",
       "[16986 rows x 2 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4003fb87-f6ea-4c1b-afef-9d4ecb92008a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16986it [00:00, 23134.21it/s]\n"
     ]
    }
   ],
   "source": [
    "data_list=[]\n",
    "for idx, row in tqdm(data.iterrows()):\n",
    "    data_list.append([row[0], row[1]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8a593fee-73e9-4337-88b0-f9296ac97d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 128\n",
    "batch_size = 64\n",
    "warmup_ratio = 0.1\n",
    "num_epochs = 10\n",
    "max_grad_norm = 1\n",
    "log_interval = 200\n",
    "learning_rate = 5e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "149ec05b-2dab-45d8-8834-6f2b22239376",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습\n",
    "# Train / Test set 분리\n",
    "dataset_train, dataset_test = train_test_split(data_list, test_size=0.2, random_state=0)\n",
    "\n",
    "# 학습을 위한 데이터셋 구축\n",
    "data_train = BERTDataset(dataset_train, 0, 1, tok, max_len, True, False)\n",
    "data_test = BERTDataset(dataset_test, 0, 1, tok, max_len, True, False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b1bc44e0-04b5-4dd8-a1f0-c91dcd6af0c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "######  tmp\n",
    "# 학습 데이터셋 구축 클래스\n",
    "class BERTDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, dataset, sent_idx, label_idx, bert_tokenizer, max_len,\n",
    "                 pad, pair):\n",
    "        transform = nlp.data.BERTSentenceTransform(\n",
    "            bert_tokenizer, max_seq_length=max_len, pad=pad, pair=pair)\n",
    "        print(transform)\n",
    "\n",
    "        self.sentences = [transform([i[sent_idx]]) for i in dataset]\n",
    "        print(self.sentences)\n",
    "        self.labels = [np.int32(i[label_idx]) for i in dataset]\n",
    "        print(self.labels)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return (self.sentences[i] + (self.labels[i], ))\n",
    "\n",
    "    def __len__(self):\n",
    "        return (len(self.labels))\n",
    "######  tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "162e6d83-bdfb-4fcb-bbd6-271c52f8d6b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from gluonnlp.data import SentencepieceTokenizer\n",
    "# from kobert import get_tokenizer\n",
    "# tok_path = get_tokenizer()\n",
    "# sp  = SentencepieceTokenizer(tok_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8db46c9f-3c3f-4cd8-b092-8129ae6ad9b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sp('5일장')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0a075cfe-be17-4fc5-9997-87bb637511f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# pytorch용 DataLoader 사용\n",
    "train_dataloader = torch.utils.data.DataLoader(data_train, batch_size=batch_size, num_workers=5)\n",
    "test_dataloader = torch.utils.data.DataLoader(data_test, batch_size=batch_size, num_workers=5)\n",
    "\n",
    "# 옵티마이저 선언\n",
    "optimizer = AdamW(optimizer_grouped_parameters, lr=learning_rate)\n",
    "loss_fn = nn.CrossEntropyLoss() # softmax용 Loss Function 정하기 <- binary classification도 해당 loss function 사용 가능\n",
    "\n",
    "# warm_up\n",
    "t_total = len(train_dataloader) * num_epochs\n",
    "warmup_step = int(t_total * warmup_ratio)\n",
    "\n",
    "# 스케쥴러\n",
    "scheduler = get_cosine_schedule_with_warmup(optimizer, num_warmup_steps=warmup_step, num_training_steps=t_total)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de668877-cc65-408c-bb8e-16ee6f0d64ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:03,  3.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 batch id 1 loss 5.004242897033691 train acc 0.015625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "201it [01:27,  2.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 batch id 201 loss 1.511103630065918 train acc 0.42428482587064675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "213it [01:32,  2.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 train acc 0.451056338028169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "54it [00:08,  6.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 test acc 0.9074074074074074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  1.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2 batch id 1 loss 1.4317032098770142 train acc 0.890625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "32it [00:13,  2.36it/s]"
     ]
    }
   ],
   "source": [
    "for e in range(num_epochs):\n",
    "    train_acc = 0.0\n",
    "    test_acc = 0.0\n",
    "    model.train()\n",
    "    for batch_id, (token_ids, valid_length, segment_ids, label) in tqdm(enumerate(train_dataloader)):\n",
    "        optimizer.zero_grad()\n",
    "        token_ids = token_ids.long().to(device)\n",
    "        segment_ids = segment_ids.long().to(device)\n",
    "        valid_length= valid_length\n",
    "        label = label.long().to(device)\n",
    "        out, hidden = model(token_ids, valid_length, segment_ids)\n",
    "        loss = loss_fn(out, label)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
    "        optimizer.step()\n",
    "        scheduler.step()  # Update learning rate schedule\n",
    "        train_acc += calc_accuracy(out, label)\n",
    "        if batch_id % log_interval == 0:\n",
    "            print(\"epoch {} batch id {} loss {} train acc {}\".format(e+1, batch_id+1, loss.data.cpu().numpy(), train_acc / (batch_id+1)))\n",
    "\n",
    "    print(\"epoch {} train acc {}\".format(e+1, train_acc / (batch_id+1)))\n",
    "\n",
    "\n",
    "    model.eval()\n",
    "    for batch_id, (token_ids, valid_length, segment_ids, label) in tqdm(enumerate(test_dataloader)):\n",
    "        token_ids = token_ids.long().to(device)\n",
    "        segment_ids = segment_ids.long().to(device)\n",
    "        valid_length= valid_length\n",
    "        label = label.long().to(device)\n",
    "        out, hidden = model(token_ids, valid_length, segment_ids)\n",
    "        test_acc += calc_accuracy(out, label)\n",
    "    print(\"epoch {} test acc {}\".format(e+1, test_acc / (batch_id+1)))\n",
    "\n",
    "\n",
    "    # GPU 사용시 학습 전 캐시제거\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f027e0f7-c959-4c2e-8b5b-70c69cde1f1f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 모델 로컬 저장\n",
    "torch.save(model, f'./result_m.pt')\n",
    "torch.save(model.state_dict(), f'./result_state_dict.pt')  # 모델 객체의 state_dict 저장\n",
    "torch.save({\n",
    "    'model': model.state_dict(),\n",
    "    'optimizer': optimizer.state_dict()\n",
    "}, f'./result.tar')  # 여러 가지 값 저장, 학습 중 진행 상황 저장을 위해 epoch, loss 값 등 일반 scalar값 저장 가능\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d13e53-5763-4336-a406-1041754df6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model load\n",
    "model_loaded = torch.load(f'./result_m.pt')  # 전체 모델을 통째로 불러옴, 클래스 선언 필수\n",
    "model_loaded.load_state_dict(torch.load(f'./result_state_dict.pt'))  # state_dict를 불러 온 후, 모델에 저장\n",
    "checkpoint = torch.load(f'./result.tar')   # dict 불러오기\n",
    "model_loaded.load_state_dict(checkpoint['model'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38078f4c-de53-43cf-9802-fab95f3805c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예측값의 확률 값을 출력하기 위한 함수\n",
    "def softmax(logits):\n",
    "    argmax = torch.argmax(logits).item()\n",
    "    sum_exp = torch.exp(logits).sum().item()\n",
    "    argmax_exp = torch.exp(logits)[argmax].item()\n",
    "    return argmax, argmax_exp/sum_exp, logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207bbfa7-d463-4323-8348-afbbed70d6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bert_predict(predict_sentence, thres = 0.5):\n",
    "\n",
    "    data = [predict_sentence, '0']\n",
    "    dataset_another = [data]\n",
    "\n",
    "    another_test = BERTDataset(dataset_another, 0, 1, tok, max_len, True, False)\n",
    "    test_dataloader = torch.utils.data.DataLoader(another_test, batch_size=batch_size, num_workers=5)\n",
    "\n",
    "    model_loaded.eval()\n",
    "\n",
    "    for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(test_dataloader):\n",
    "\n",
    "        token_ids = token_ids.long().to(device)\n",
    "        segment_ids = segment_ids.long().to(device)\n",
    "\n",
    "        valid_length= valid_length\n",
    "        label = label.long().to(device)\n",
    "\n",
    "        out, sentence_vector = model_loaded(token_ids, valid_length, segment_ids)\n",
    "#         print(out, sentence_vector)\n",
    "\n",
    "\n",
    "        for i in out:\n",
    "\n",
    "            argmax, prob, logits = softmax(i)\n",
    "\n",
    "    return argmax, prob, logits # sentence_vector,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568ffd1a-644a-4505-bacc-39b211977f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "testset = pd.read_csv('./test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f699f40-a752-4f92-92ff-7d58277941c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sentences = testset['overview'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866ed962-7c8a-4a88-befb-d02c7008df72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# before\n",
    "pred = []\n",
    "for i in tqdm(test_sentences):\n",
    "    pred.append(num_to_chr[bert_predict(i)[0]])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e78ad208-d882-42c2-b950-d9d790b41a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pred = []\n",
    "for i in tqdm(test_sentences):\n",
    "    pred.append(num_to_chr[bert_predict(i)[0]])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "235196b8-509b-4b78-a4da-fecf7f722830",
   "metadata": {},
   "outputs": [],
   "source": [
    "testset['cat3'] = pred\n",
    "testset[['id', 'cat3']].to_csv('kobert_add_label.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566b1144-77a9-4fba-8b2c-4105868b09c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
